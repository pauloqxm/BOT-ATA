import os
import time
import warnings
import tempfile

# =============================
# Ajustes de ambiente
# =============================
os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"
os.environ["KMP_DUPLICATE_LIB_OK"] = "True"
warnings.filterwarnings("ignore", message=".*huggingface_hub.*")

import torch

# tentar espremer a CPU sem brigar com o Streamlit
num_threads = os.cpu_count() or 4
try:
    torch.set_num_threads(num_threads)
except RuntimeError:
    # se o PyTorch reclamar porque j√° tem thread rodando, ignora
    pass
os.environ["OMP_NUM_THREADS"] = str(num_threads)

import librosa
import soundfile as sf  # ainda pode ser √∫til depois
import streamlit as st

# Whisper oficial (CPU/GPU NVIDIA)
import whisper

# =============================
# Config Streamlit
# =============================
st.set_page_config(
    page_title="Transcri√ß√£o ATA ‚Äì Whisper oficial",
    layout="wide",
)

st.title("üìù Transcri√ß√£o de Ata ‚Äì Whisper oficial")
st.caption(
    "Usa exclusivamente o Whisper oficial da OpenAI. "
    "Voc√™ escolhe o modelo e ele ser√° mantido, mesmo que fique mais lento na CPU."
)

# =============================
# Estado da biblioteca de corre√ß√µes
# =============================
if "correcoes_custom" not in st.session_state:
    st.session_state["correcoes_custom"] = {}


# =============================
# Utilit√°rios gerais
# =============================
BASE_PROMPT = (
    "Transcri√ß√£o em portugu√™s brasileiro formal, com pontua√ß√£o correta, "
    "acentua√ß√£o adequada e frases completas. Use nomes pr√≥prios, siglas e "
    "termos t√©cnicos conforme aparecem no √°udio. Evite inventar trechos."
)


def get_correcoes_dicionario():
    """Dicion√°rio base + dicion√°rio customizado vindo da aba Biblioteca."""
    correcoes_base = {
        " pq ": " porque ",
        " tb ": " tamb√©m ",
        " vc ": " voc√™ ",
        " d ": " de ",
        " q ": " que ",
        " ta ": " est√° ",
        " tava ": " estava ",
        " pra ": " para ",
        " ne ": " n√£o √© ",
        " naum ": " n√£o ",
        " entao ": " ent√£o ",
        " tbm ": " tamb√©m ",
        " obg ": " obrigado ",
        " vlw ": " valeu ",
        " blz ": " beleza ",
        " p ": " para ",
        " cm ": " com ",
        " td ": " tudo ",
        " qd ": " quando ",
        " qq ": " qualquer ",
    }
    # customizadas pelo usu√°rio, salvas com espa√ßos de margem
    correcoes_custom = st.session_state.get("correcoes_custom", {})
    correcoes = {}
    correcoes.update(correcoes_base)
    correcoes.update(correcoes_custom)
    return correcoes


def pos_processar_texto(texto: str) -> str:
    if not texto:
        return ""

    correcoes = get_correcoes_dicionario()

    texto = " " + texto + " "
    for errado, correto in correcoes.items():
        texto = texto.replace(errado, correto)

    while "  " in texto:
        texto = texto.replace("  ", " ")

    texto = (
        texto.replace(" .", ".")
        .replace(" ,", ",")
        .replace(" ?", "?")
        .replace(" !", "!")
    )

    return texto.strip()


def dividir_em_chunks(audio, sr, chunk_seg=120):
    partes = []
    tam = int(chunk_seg * sr)
    total = len(audio)
    for i in range(0, total, tam):
        parte = audio[i : i + tam]
        t_ini = i / sr
        t_fim = (i + len(parte)) / sr
        partes.append((parte, t_ini, t_fim))
    return partes


def formatar_timestamps(timestamps):
    linhas = []
    for ts in timestamps:
        linhas.append(f"[{ts['start']:.1f}s - {ts['end']:.1f}s] {ts['text']}")
    return "\n".join(linhas)


# =============================
# Backend WHISPER (CPU / GPU NVIDIA)
# =============================
@st.cache_resource(show_spinner=True)
def carregar_modelo_whisper(nome_modelo: str, device: str):
    return whisper.load_model(nome_modelo, device=device)


def transcrever_com_whisper(audio, sr, modelo_nome: str, chunk_seg: int):
    if torch.cuda.is_available():
        device = "cuda"
        fp16 = True
        device_msg = f"GPU NVIDIA detectada: {torch.cuda.get_device_name(0)}"
    else:
        device = "cpu"
        fp16 = False
        device_msg = "GPU NVIDIA n√£o detectada. Usando CPU (pode ficar mais lento)."

    st.info(device_msg)

    duracao_min = len(audio) / sr / 60
    modelo_efetivo = modelo_nome  # mant√©m exatamente o modelo escolhido
    st.write(f"üéØ Whisper: modelo `{modelo_efetivo}` em `{device}`")

    with st.spinner(f"Carregando modelo Whisper {modelo_efetivo}..."):
        model = carregar_modelo_whisper(modelo_efetivo, device)

    partes = dividir_em_chunks(audio, sr, chunk_seg)
    total_partes = len(partes)
    st.write(f"üì¶ Partes processadas: **{total_partes}**")

    # barra de progresso geral (conte√∫do) e na sidebar
    progresso = st.progress(0)
    progresso_sidebar = st.sidebar.progress(0)

    texto_final = ""
    timestamps = []
    tempos_partes = []
    inicio_geral = time.time()

    for idx, (parte, t_ini, t_fim) in enumerate(partes, start=1):
        janela_min = t_ini / 60
        janela_max = t_fim / 60
        st.write(
            f"üìù Parte {idx}/{total_partes} "
            f"({janela_min:.1f}‚Äì{janela_max:.1f} min do √°udio)"
        )

        inicio_parte = time.time()
        result = model.transcribe(
            parte,
            language="pt",
            task="transcribe",
            temperature=[0.0, 0.2],
            best_of=5,
            initial_prompt=BASE_PROMPT,
            fp16=fp16,
        )
        tempo_parte = time.time() - inicio_parte
        tempos_partes.append(tempo_parte)

        segs = result.get("segments", [])
        if segs:
            for seg in segs:
                texto = seg["text"]
                start = float(seg["start"]) + t_ini
                end = float(seg["end"]) + t_ini
                timestamps.append({"start": start, "end": end, "text": texto})
                texto_final += texto + " "

            st.write(f"‚úÖ Parte {idx} conclu√≠da em {tempo_parte:.1f}s")
            st.write(f"Pr√©via: _{segs[0]['text'][:120]}..._")
        else:
            st.warning("‚ö†Ô∏è Nenhum texto detectado nesta parte.")

        progresso.progress(idx / total_partes)
        progresso_sidebar.progress(idx / total_partes)

    tempo_total = time.time() - inicio_geral
    return texto_final, timestamps, tempo_total, duracao_min, total_partes, tempos_partes


# =============================
# Sidebar ‚Äì configura√ß√µes
# =============================
st.sidebar.header("Configura√ß√µes de processamento")

chunk_segundos = st.sidebar.slider(
    "Dura√ß√£o de cada parte (segundos)",
    min_value=60,
    max_value=240,
    value=120,
    step=30,
)

# configura√ß√£o de modelo Whisper
modelos = {
    "tiny ‚Äì mais r√°pido (menos preciso)": "tiny",
    "base ‚Äì equil√≠brio recomendado": "base",
    "small ‚Äì mais preciso (mais pesado)": "small",
    "medium ‚Äì alta precis√£o (pesado)": "medium",
    "large-v3 ‚Äì m√°xima precis√£o (muito pesado)": "large-v3",
}
modelo_label = st.sidebar.selectbox(
    "Modelo Whisper",
    list(modelos.keys()),
    index=1,
)
modelo_whisper = modelos[modelo_label]


# =============================
# Abas principais
# =============================
tab_transcricao, tab_biblioteca = st.tabs(
    ["üéß Transcri√ß√£o", "üß© Biblioteca de corre√ß√µes"]
)

# =============================
# Aba 1 ‚Äì Transcri√ß√£o
# =============================
with tab_transcricao:
    # Upload de √°udio
    audio_file = st.file_uploader(
        "Envie o arquivo de √°udio da sess√£o/ata",
        type=["mp3", "wav", "m4a", "ogg", "flac", "aac", "wma"],
    )

    if audio_file is not None:
        st.success(f"Arquivo carregado. Nome: {audio_file.name}")
        tamanho_mb = audio_file.size / 1024 / 1024
        st.write(f"Tamanho aproximado: {tamanho_mb:.2f} MB")
    else:
        tamanho_mb = 0.0

    # Bot√£o principal
    if st.button("üöÄ Transcrever agora", disabled=(audio_file is None)):
        if audio_file is None:
            st.warning("Envie um arquivo de √°udio primeiro.")
        else:
            with tempfile.NamedTemporaryFile(delete=False, suffix=audio_file.name) as tmp:
                tmp.write(audio_file.read())
                caminho_audio = tmp.name

            try:
                # Pr√©-processar √°udio
                with st.spinner("üîß Pr√©-processando √°udio..."):
                    audio, sr_original = librosa.load(caminho_audio, sr=None, mono=True)

                    max_abs = max(1e-8, float(abs(audio).max()))
                    audio = audio / max_abs * 0.9

                    if sr_original != 16000:
                        audio = librosa.resample(
                            audio, orig_sr=sr_original, target_sr=16000
                        )
                        sr = 16000
                    else:
                        sr = sr_original

                    duracao_min_pre = len(audio) / sr / 60
                    partes_preview = dividir_em_chunks(audio, sr, chunk_segundos)
                    total_partes_preview = len(partes_preview)

                # KPIs iniciais ao ler/preparar o arquivo
                st.markdown("### üìä Vis√£o geral do arquivo")
                col_a, col_b, col_c = st.columns(3)
                col_a.metric("Dura√ß√£o do √°udio", f"{duracao_min_pre:.1f} min")
                col_b.metric("Tamanho do arquivo", f"{tamanho_mb:.2f} MB")
                col_c.metric("Quantidade de partes", f"{total_partes_preview}")

                # Transcri√ß√£o com Whisper oficial
                (
                    texto,
                    ts,
                    tempo_proc,
                    duracao_min,
                    total_partes,
                    tempos_partes,
                ) = transcrever_com_whisper(
                    audio, sr, modelo_whisper, chunk_segundos
                )

                texto = pos_processar_texto(texto)

                if not texto.strip():
                    st.error(
                        "Nenhum texto final gerado. Verifique se o √°udio tem fala clara."
                    )
                else:
                    st.success("üéâ Transcri√ß√£o conclu√≠da com sucesso.")

                    # KPIs p√≥s-processamento
                    st.markdown("### üìà Indicadores de processamento")
                    col1, col2 = st.columns(2)
                    col1.metric("Dura√ß√£o do √°udio", f"{duracao_min:.1f} min")
                    col2.metric("Tempo total de processamento", f"{tempo_proc:.1f} s")

                    # Barras de desempenho por parte (gr√°fico de barras)
                    if tempos_partes:
                        st.markdown("### üìä Desempenho por parte")
                        dados_barra = {
                            "Parte": list(range(1, total_partes + 1)),
                            "Tempo (s)": tempos_partes,
                        }
                        st.bar_chart(dados_barra, x="Parte", y="Tempo (s)")

                    # Texto final ‚Äì apenas 400 caracteres na interface
                    st.subheader("üßæ Texto da Ata (pr√©via ‚Äì 400 caracteres)")
                    preview = texto[:400]
                    if len(texto) > 400:
                        preview += "..."
                    st.write(preview)

                    # Timestamps completos
                    st.subheader("‚è±Ô∏è Timestamps")
                    texto_ts = formatar_timestamps(ts)
                    st.text(texto_ts)

                    # Downloads ‚Äì texto completo
                    nome_base = os.path.splitext(audio_file.name)[0]
                    st.download_button(
                        "üì• Baixar transcri√ß√£o completa (.txt)",
                        data=texto,
                        file_name=f"TRANSCRICAO_{nome_base}.txt",
                        mime="text/plain",
                    )
                    st.download_button(
                        "üì• Baixar timestamps (.txt)",
                        data=texto_ts,
                        file_name=f"TIMESTAMPS_{nome_base}.txt",
                        mime="text/plain",
                    )

            finally:
                try:
                    os.unlink(caminho_audio)
                except Exception:
                    pass
    else:
        st.info("Envie o √°udio e clique em 'üöÄ Transcrever agora'.")


# =============================
# Aba 2 ‚Äì Biblioteca de corre√ß√µes
# =============================
with tab_biblioteca:
    st.markdown("### üß© Palavras e express√µes para corre√ß√£o autom√°tica")
    st.write(
        "Aqui voc√™ pode adicionar palavras ou abrevia√ß√µes que ser√£o trocadas "
        "automaticamente na p√≥s-edi√ß√£o da transcri√ß√£o."
    )
    st.write(
        "Dica: use a forma como voc√™ costuma falar/escrever no √°udio em "
        "`Original` e a forma correta em `Substituir por`."
    )

    # Exibe dicion√°rio base + customizado (somente leitura para o base)
    st.markdown("#### Corre√ß√µes atuais em uso (base + customizadas)")
    dicionario_atual = get_correcoes_dicionario()
    if dicionario_atual:
        orig = []
        novo = []
        for k, v in dicionario_atual.items():
            orig.append(k.strip())
            novo.append(v.strip())
        st.table({"Original": orig, "Substituir por": novo})
    else:
        st.info("Nenhuma corre√ß√£o cadastrada.")

    st.markdown("#### Adicionar nova corre√ß√£o personalizada")
    with st.form("form_add_correcao"):
        col1, col2 = st.columns(2)
        with col1:
            original = st.text_input("Original (palavra/express√£o)")
        with col2:
            substituir = st.text_input("Substituir por")

        submitted = st.form_submit_button("Adicionar corre√ß√£o")
        if submitted:
            if not original.strip() or not substituir.strip():
                st.error("Preencha os dois campos antes de adicionar.")
            else:
                chave = f" {original.strip()} "
                valor = f" {substituir.strip()} "
                st.session_state["correcoes_custom"][chave] = valor
                st.success(
                    f"Corre√ß√£o adicionada: '{original.strip()}' ‚Üí '{substituir.strip()}'"
                )
