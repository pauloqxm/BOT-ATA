import os
import sys
import time
import warnings

# Ajustes de ambiente
os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'
os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'
warnings.filterwarnings("ignore", message=".*huggingface_hub.*")

import torch
import whisper
import librosa


# Se quiser testar o pr√©-√™nfase em √°udios muito abafados, mude para True
USE_PREEMPHASIS = False


class BarraProgresso:
    def __init__(self, total, descricao="", comprimento=40):
        self.total = max(1, total)
        self.descricao = descricao
        self.comprimento = comprimento
        self.atual = 0
        self.inicio_tempo = time.time()
    
    def atualizar(self, progresso=1):
        self.atual += progresso
        if self.atual > self.total:
            self.atual = self.total
        percentual = min(100, (self.atual / self.total) * 100)
        barras_preenchidas = int(self.comprimento * self.atual // self.total)
        barra = '‚ñà' * barras_preenchidas + '‚ñë' * (self.comprimento - barras_preenchidas)
        tempo_decorrido = time.time() - self.inicio_tempo
        if self.atual > 0:
            tempo_estimado = (tempo_decorrido / self.atual) * (self.total - self.atual)
        else:
            tempo_estimado = 0
        tempo_decorrido_str = self._formatar_tempo(tempo_decorrido)
        tempo_estimado_str = self._formatar_tempo(tempo_estimado)
        sys.stdout.write('\r')
        sys.stdout.write(
            f"{self.descricao} |{barra}| {percentual:.1f}% ({self.atual}/{self.total}) "
            f"[{tempo_decorrido_str}<{tempo_estimado_str}]"
        )
        sys.stdout.flush()
        if self.atual >= self.total:
            sys.stdout.write('\n')
    
    def _formatar_tempo(self, segundos):
        if segundos < 60:
            return f"{int(segundos)}s"
        elif segundos < 3600:
            return f"{int(segundos//60)}m{int(segundos%60)}s"
        else:
            return f"{int(segundos//3600)}h{int((segundos%3600)//60)}m{int(segundos%60)}s"


def selecionar_arquivo():
    print("\nüìÅ SELECIONAR ARQUIVO DE √ÅUDIO")
    print("=" * 40)
    print("1. üìÇ Usar arquivo local (digitar caminho)")
    print("2. üóÇÔ∏è Listar arquivos na pasta atual")
    print("3. üö™ Sair")
    
    while True:
        opcao = input("\nüëâ Escolha uma op√ß√£o (1-3): ").strip()
        if opcao == "1":
            return arquivo_local()
        elif opcao == "2":
            return listar_arquivos()
        elif opcao == "3":
            print("üëã At√© logo!")
            return None
        else:
            print("‚ùå Op√ß√£o inv√°lida. Tente novamente.")


def arquivo_local():
    print("\nüìÇ ARQUIVO LOCAL")
    print("=" * 30)
    print("Exemplos de caminho:")
    print("‚Ä¢ C:\\Users\\Usuario\\Downloads\\audio.mp3")
    print("‚Ä¢ audio.mp3 (se estiver na mesma pasta)")
    print("‚Ä¢ ..\\pasta\\audio.wav")
    
    caminho = input("\nüìÅ Digite o caminho do arquivo: ").strip()
    caminho = caminho.replace('"', '').replace("'", '')
    
    if not caminho:
        print("‚ùå Nenhum caminho fornecido")
        return None
    
    if not os.path.exists(caminho):
        print(f"‚ùå Arquivo n√£o encontrado: {caminho}")
        print("üí° Verifique se o caminho est√° correto")
        return None
    
    print(f"‚úÖ Arquivo encontrado: {os.path.basename(caminho)}")
    return caminho


def listar_arquivos():
    print("\nüóÇÔ∏è ARQUIVOS NA PASTA ATUAL")
    print("=" * 40)
    
    extensoes = ('.mp3', '.wav', '.m4a', '.ogg', '.flac', '.aac', '.wma')
    arquivos_audio = []
    
    for arquivo in os.listdir('.'):
        if arquivo.lower().endswith(extensoes):
            tamanho = os.path.getsize(arquivo) / 1024 / 1024
            arquivos_audio.append((arquivo, tamanho))
    
    if not arquivos_audio:
        print("‚ùå Nenhum arquivo de √°udio encontrado")
        print("üí° Formatos suportados: MP3, WAV, M4A, OGG, FLAC, AAC, WMA")
        return None
    
    print("Arquivos de √°udio encontrados:")
    for i, (arquivo, tamanho) in enumerate(arquivos_audio, 1):
        print(f"  {i}. {arquivo} ({tamanho:.1f} MB)")
    
    print(f"\nTotal: {len(arquivos_audio)} arquivo(s)")
    
    try:
        escolha = input(f"\nüëâ Digite o n√∫mero do arquivo (1-{len(arquivos_audio)}) ou Enter para voltar: ").strip()
        if not escolha:
            return None
        indice = int(escolha) - 1
        if 0 <= indice < len(arquivos_audio):
            arquivo_escolhido = arquivos_audio[indice][0]
            print(f"üéØ Arquivo selecionado: {arquivo_escolhido}")
            return arquivo_escolhido
        else:
            print("‚ùå N√∫mero inv√°lido")
            return None
    except ValueError:
        print("‚ùå Por favor, digite um n√∫mero v√°lido")
        return None


def processar_segmentos(segments):
    textos = []
    timestamps = []
    
    if not segments:
        return "", []
    
    for seg in segments:
        texto = seg.get("text", "").strip()
        if texto:
            textos.append(texto)
            timestamps.append({
                "start": float(seg.get("start", 0.0)),
                "end": float(seg.get("end", 0.0)),
                "text": texto
            })
    
    texto_final = " ".join(textos)
    return texto_final, timestamps


def pos_processar_texto(texto):
    correcoes = {
        " pq ": " porque ",
        " tb ": " tamb√©m ",
        " vc ": " voc√™ ",
        " d ": " de ",
        " q ": " que ",
        " ta ": " est√° ",
        " tava ": " estava ",
        " pra ": " para ",
        " ne ": " n√£o √© ",
        " naum ": " n√£o ",
        " entao ": " ent√£o ",
        " tbm ": " tamb√©m ",
        " obg ": " obrigado ",
        " vlw ": " valeu ",
        " blz ": " beleza ",
        " p ": " para ",
        " cm ": " com ",
        " td ": " tudo ",
        " qd ": " quando ",
        " qq ": " qualquer ",
    }
    
    for errado, correto in correcoes.items():
        texto = texto.replace(errado, correto)
    
    texto = texto.replace(" .", ".").replace(" ,", ",").replace(" ?", "?").replace(" !", "!")
    
    while "  " in texto:
        texto = texto.replace("  ", " ")
    
    texto = texto.strip()
    if texto and len(texto) > 1:
        texto = texto[0].upper() + texto[1:]
    
    return texto


def salvar_resultados(texto, timestamps, nome_base, duracao):
    from datetime import datetime
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    barra_salvamento = BarraProgresso(2, "Salvando arquivos", 30)
    
    nome_principal = f"TRANSCRICAO_{nome_base}_{timestamp}.txt"
    with open(nome_principal, 'w', encoding='utf-8') as f:
        f.write("TRANSCRI√á√ÉO DE ALTA PRECIS√ÉO - PORTUGU√äS BRASILEIRO\n")
        f.write(f"Arquivo: {nome_base}\n")
        f.write(f"Dura√ß√£o: {duracao/60:.1f} minutos\n")
        f.write(f"Data: {datetime.now().strftime('%d/%m/%Y %H:%M')}\n")
        f.write("="*50 + "\n\n")
        f.write(texto)
    barra_salvamento.atualizar(1)
    
    nome_timestamps = f"TIMESTAMPS_{nome_base}_{timestamp}.txt"
    with open(nome_timestamps, 'w', encoding='utf-8') as f:
        for ts in timestamps:
            f.write(f"[{ts['start']:.1f}s - {ts['end']:.1f}s] {ts['text']}\n")
    barra_salvamento.atualizar(1)
    
    palavras = len(texto.split())
    print(f"\nüíæ ARQUIVOS SALVOS:")
    print(f"   üìÑ {nome_principal}")
    print(f"   ‚è±Ô∏è {nome_timestamps}")
    print(f"\nüìä ESTAT√çSTICAS:")
    print(f"   ‚Ä¢ Palavras: {palavras}")
    print(f"   ‚Ä¢ Caracteres: {len(texto)}")
    print(f"   ‚Ä¢ Segmentos: {len(timestamps)}")
    print(f"   ‚Ä¢ Dura√ß√£o √°udio: {duracao/60:.1f} min")
    
    print(f"\nüìÑ PR√âVIA (primeiras 400 caracteres):")
    print("-" * 50)
    print(texto[:400] + "..." if len(texto) > 400 else texto)
    print("-" * 50)


def transcrever_com_precisao():
    print("üéØ TRANSCRI√á√ÉO HIGH-ACCURACY PT-BR (GPU se dispon√≠vel)")
    print("=" * 70)
    
    caminho_audio = selecionar_arquivo()
    if not caminho_audio:
        return
    
    if torch.cuda.is_available():
        DEVICE = "cuda"
        fp16 = True
        print("\nüíª Usando GPU (CUDA)")
        print("   GPU:", torch.cuda.get_device_name(0))
    else:
        DEVICE = "cpu"
        fp16 = False
        print("\nüíª Usando CPU (CUDA n√£o dispon√≠vel)")
    
    try:
        print(f"\n‚úÖ Processando: {os.path.basename(caminho_audio)}")
        
        try:
            n_threads = max(1, os.cpu_count() or 4)
            torch.set_num_threads(n_threads)
            print(f"üß† Threads CPU configuradas: {n_threads}")
        except Exception as e:
            print(f"‚ö†Ô∏è N√£o consegui ajustar threads da CPU: {e}")
        
        print("\nüîß Configura√ß√µes de qualidade:")
        print("1. üöÄ R√°pido (tiny)")
        print("2. ‚öñÔ∏è Balanceado (base)")
        print("3. üéØ Preciso (small)")
        print("4. üèÜ Alta qualidade (medium)")
        print("5. üèÖ M√°xima precis√£o (large-v3)")
        
        modelo_opcao = input("Escolha o modelo (1-5, padr√£o=4): ").strip() or "4"
        modelos = {"1": "tiny", "2": "base", "3": "small", "4": "medium", "5": "large-v3"}
        MODELO = modelos.get(modelo_opcao, "medium")
        print(f"üéØ Usando modelo: {MODELO}")
        
        BASE_PROMPT = (
            "Transcri√ß√£o em portugu√™s brasileiro formal, com pontua√ß√£o correta, "
            "acentua√ß√£o adequada e frases completas. Use nomes pr√≥prios, siglas e "
            "termos t√©cnicos conforme aparecem no √°udio. Evite inventar trechos."
        )
        
        # Configura√ß√£o base para decodifica√ß√£o com foco em qualidade
        CONFIG_TRANSCRICAO_BASE = {
            "language": "pt",
            "task": "transcribe",
            "temperature": [0.0, 0.2, 0.4],
            "best_of": 5,
            "beam_size": None,          # beam search desativado quando usamos multi-temperatura
            "patience": None,
            "compression_ratio_threshold": 2.4,
            "logprob_threshold": -1.0,
            "no_speech_threshold": 0.3,
            "condition_on_previous_text": False,  # vamos controlar contexto via prompt
            "verbose": False,
            "fp16": fp16,
            "initial_prompt": BASE_PROMPT,
        }
        
        print("\nüîß Pr√©-processando √°udio...")
        audio, sr_original = librosa.load(caminho_audio, sr=None, mono=True)
        
        # Normaliza√ß√£o mais suave e segura
        max_abs = max(1e-8, float(abs(audio).max()))
        audio = audio / max_abs * 0.9
        
        # Pr√©-√™nfase opcional
        if USE_PREEMPHASIS:
            audio = librosa.effects.preemphasis(audio, coef=0.97)
        
        # Padronizar para 16 kHz
        if sr_original != 16000:
            audio = librosa.resample(audio, orig_sr=sr_original, target_sr=16000)
            sr = 16000
        else:
            sr = sr_original
        
        duracao_total = len(audio) / sr
        print(f"üìä Dura√ß√£o total: {duracao_total/60:.1f} minutos")
        
        # Dividir em partes de 2 minutos
        CHUNK_DURACAO_SEG = 120
        amostras_por_chunk = int(CHUNK_DURACAO_SEG * sr)
        n_chunks = (len(audio) + amostras_por_chunk - 1) // amostras_por_chunk
        
        print(f"üî™ √Åudio ser√° dividido em {n_chunks} parte(s) de at√© {CHUNK_DURACAO_SEG} segundos")
        
        print(f"\nüîß Carregando modelo {MODELO} em {DEVICE}...")
        model = whisper.load_model(MODELO, device=DEVICE)
        print("‚úÖ Modelo carregado.")
        
        print("\nüéØ Iniciando transcri√ß√£o em chunks de 2 minutos...")
        inicio = time.time()
        
        todos_segments = []
        total_amostras = len(audio)
        barra_chunks = BarraProgresso(total_amostras, "Transcrevendo √°udio", 40)
        
        for i in range(n_chunks):
            start_sample = i * amostras_por_chunk
            end_sample = min(len(audio), (i + 1) * amostras_por_chunk)
            chunk_audio = audio[start_sample:end_sample]
            chunk_amostras = end_sample - start_sample
            
            offset_segundos = start_sample / sr
            inicio_parte = time.time()
            
            print(f"\nüìù Parte {i+1}/{n_chunks} "
                  f"({offset_segundos/60:.1f}‚Äì{min(duracao_total, offset_segundos + chunk_amostras/sr)/60:.1f} min)")
            
            # Construir prompt com contexto dos √∫ltimos segmentos
            if i == 0 or not todos_segments:
                config_chunk = CONFIG_TRANSCRICAO_BASE
            else:
                ultimo_contexto = " ".join(
                    seg.get("text", "").strip()
                    for seg in todos_segments[-12:]
                    if seg.get("text")
                ).strip()
                
                if ultimo_contexto:
                    contexto_prompt = (
                        BASE_PROMPT
                        + " Contexto anterior da conversa para manter coer√™ncia e nomes pr√≥prios: "
                        + ultimo_contexto[-400:]
                    )
                else:
                    contexto_prompt = BASE_PROMPT
                
                config_chunk = {
                    **CONFIG_TRANSCRICAO_BASE,
                    "initial_prompt": contexto_prompt,
                }
            
            result_chunk = model.transcribe(chunk_audio, **config_chunk)
            segments_chunk = result_chunk.get("segments", [])
            
            trecho_previa = " ".join(
                seg.get("text", "").strip()
                for seg in segments_chunk
                if seg.get("text")
            ).strip()
            if trecho_previa:
                print(f"   üìÑ Pr√©via: {trecho_previa[:120]}...")
            else:
                print("   üìÑ Pr√©via: [sem texto detectado]")
            
            for seg in segments_chunk:
                novo_seg = seg.copy()
                novo_seg["start"] = float(seg.get("start", 0.0)) + offset_segundos
                novo_seg["end"] = float(seg.get("end", 0.0)) + offset_segundos
                todos_segments.append(novo_seg)
            
            tempo_parte = time.time() - inicio_parte
            print(f"   ‚è±Ô∏è Parte conclu√≠da em {tempo_parte:.1f}s")
            
            barra_chunks.atualizar(chunk_amostras)
        
        tempo_total = time.time() - inicio
        print(f"\n‚úÖ Transcri√ß√£o conclu√≠da em {tempo_total/60:.1f} minutos de processamento.")
        
        texto_completo, timestamps = processar_segmentos(todos_segments)
        
        print("\nüîß Aplicando p√≥s-processamento avan√ßado...")
        barra_pos = BarraProgresso(3, "P√≥s-processamento", 30)
        
        texto_completo = pos_processar_texto(texto_completo)
        barra_pos.atualizar(1)
        time.sleep(0.2)
        
        texto_completo = pos_processar_texto(texto_completo)
        barra_pos.atualizar(1)
        time.sleep(0.2)
        
        texto_completo = texto_completo.strip()
        barra_pos.atualizar(1)
        
        nome_base = os.path.basename(caminho_audio).split('.')[0]
        salvar_resultados(texto_completo, timestamps, nome_base, duracao_total)
        
        print("\nüéâ TRANSCRI√á√ÉO CONCLU√çDA COM SUCESSO!")
        print("   ‚úÖ Configura√ß√µes focadas em qualidade para portugu√™s brasileiro")
        print("   ‚úÖ Contexto entre chunks via prompt")
        print("   ‚úÖ Arquivos salvos com timestamps")
        
        return texto_completo
    
    except Exception as e:
        print(f"‚ùå Erro: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    transcrever_com_precisao()
